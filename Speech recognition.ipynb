{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582a6085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Create Jupyter widgets to create buttons\\n2. Install pyaudio to record microphone\\n3. vosk does speech recognition\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Create Jupyter widgets to create buttons\n",
    "2. Install pyaudio to record microphone\n",
    "3. vosk does speech recognition\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c610790c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c19e9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c28ea41ca74f30bd0faeba65fb5e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b8fefae7c24115bcf7d43fb7447f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da64dc5d7ce2436b9bf46684cacc1cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    }
   ],
   "source": [
    "# 1. creating widgets\n",
    "import ipywidgets as widgets #helps create the toggle buttons\n",
    "from IPython.display import display #helps to display the button\n",
    "from threading import Thread #to run processes in the background\n",
    "from queue import Queue #passes messages between threads\n",
    "\n",
    "messages = Queue() #tells the thread when to stop recording and transcribing\n",
    "recordings = Queue() #stores the recordings and passes it to the transcription\n",
    "\n",
    "\n",
    "record_button = widgets.Button(\n",
    "    description = \"Record\", #text that appears on the button\n",
    "    disabled = False,\n",
    "    button_style = \"success\", #color of the button is green\n",
    "    icon = \"microphone\"\n",
    ")\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description = \"Stop\",\n",
    "    disabled = False,\n",
    "    button_style = \"warning\",\n",
    "    icon = \"stop\"\n",
    ")\n",
    "\n",
    "output = widgets.Output() #helps show the transcript, creates an instance of the output widget\n",
    "\n",
    "\n",
    "# need to create threads so that more than one process can run at the same time\n",
    "# in this case the recording and transcribing for the audio must happen at the same time\n",
    "# need to pass messages to the thread\n",
    "\n",
    "\n",
    "def start_recording(data): #Ipython passes the data to this function on clicking the record button\n",
    "    messages.put(True) #keep recording, put the message on the queue\n",
    "    \n",
    "    with output: #print data into output widget\n",
    "        display('Starting...')\n",
    "        \n",
    "        #creating threads that run in the background\n",
    "        record = Thread(target = record_microphone) #creates a thread which starts recording\n",
    "        record.start() #starts the recording\n",
    "        \n",
    "        transcribe = Thread(target = speech_recognition, args=(output,))\n",
    "        transcribe.start()\n",
    "\n",
    "def stop_recording(data):\n",
    "    with output:\n",
    "        messages.get() #gets the message off the queue\n",
    "        display('Stopped.')\n",
    "        \n",
    "record_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "display(record_button)\n",
    "display(stop_button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e242e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyaudio\n",
    "#records system audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b062b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone (2- High Definition ', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'Speakers (2- High Definition Au', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'Primary Sound Capture Driver', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Microphone (2- High Definition Audio Device)', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': 'Primary Sound Driver', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'Speakers (2- High Definition Audio Device)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': 'Speakers (2- High Definition Audio Device)', 'hostApi': 2, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.0026666999999999997, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 9, 'structVersion': 2, 'name': 'Microphone (2- High Definition Audio Device)', 'hostApi': 2, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.0029024999999999997, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.0101587, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 10, 'structVersion': 2, 'name': 'Microphone (HD Audio Microphone)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 11, 'structVersion': 2, 'name': 'Speakers (HD Audio Speaker)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio() #connects to the system sound devices\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i)) #displays all the connected sound devices\n",
    "p.terminate() #yerminates pyaudio connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a16e9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.listening to the audio\n",
    "CHANNELS = 1 #listens from only one channel\n",
    "FRAME_RATE = 16000 #quality of sound, how quickly the audio is sampled\n",
    "RECORD_SECONDS = 20 #gap between recording and transcript\n",
    "AUDIO_FORMAT = pyaudio.paInt16\n",
    "SAMPLE_SIZE = 2 \n",
    " \n",
    "def record_microphone(chunk=1024): #chunk is - how often the audio is being read\n",
    "    p = pyaudio.PyAudio()\n",
    " \n",
    "    stream = p.open(format=AUDIO_FORMAT, \n",
    "                    channels = CHANNELS,\n",
    "                    rate = FRAME_RATE,\n",
    "                    input = True,\n",
    "                    input_device_index = 2, #microphone index\n",
    "                    frames_per_buffer = chunk)\n",
    "    \n",
    "    frames = [] #stores all the audio recordings\n",
    "     \n",
    "    while not messages.empty(): #recording until the message queue is empty (stopped)\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "         \n",
    "        if len(frames) >= (FRAME_RATE * RECORD_SECONDS)/chunk : #if audio is recorrded for more than 20s\n",
    "            recordings.put(frames.copy()) #add the audio to the recordings thread queue by copying frames\n",
    "            frames=[] #empty the frame\n",
    "     \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077ed62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.recognizing live speech into text\n",
    "# !pip install vosk \n",
    "#no punctuation in speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051ee0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers \n",
    "#adds punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71a66e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch \n",
    "#to use recasepunc, to add punctuations into the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d24110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess #separate process to add punctuations by calling the command on the cmd (from transformers)\n",
    "import json \n",
    "from vosk import Model, KaldiRecognizer \n",
    "import time\n",
    "\n",
    "model = Model(model_name=\"vosk-model-small-en-us-0.15\") #speech recognition model\n",
    "rec = KaldiRecognizer(model, FRAME_RATE) #uses the model to do speech recognition\n",
    "rec.SetWords(True) #gives a probability on the confidence of the system recognizing voice\n",
    "\n",
    "def speech_recognition(output):\n",
    "    while not messages.empty(): # until stop button has been used\n",
    "        frames = recordings.get() #using the audio captured\n",
    "        \n",
    "        rec.AcceptWaveform(b''.join(frames)) #all the chunks of audio is been put into one binary string\n",
    "        result = rec.Result()\n",
    "        text = json.loads(result)[\"text\"] #vosk returns in json , so converting that into text\n",
    "        \n",
    "        cased = subprocess.check_output(\"python recasepunc/recasepunc.py predict recasepunc/checkpoint\",shell = True, text = True, input = text)\n",
    "        #adds punctuations to the transcript\n",
    "        #checkpoint is the trained model used for prediction\n",
    "        #it uses the user shell to run\n",
    "        #it takes the text variable as the input\n",
    "        #recasepunc.py helps in recasing\n",
    "        #this will reload the model every 20s\n",
    "        #not the most efficient\n",
    "        \n",
    "        output.append_stdout(cased) #adding it to the output widget\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92fca54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b067eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
